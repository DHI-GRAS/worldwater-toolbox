{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World Water Toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of the processing chain of using the World Water Toolbox with the openEO Platform. \n",
    "The Processing chain is divided to 3 main sub-flows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![flow](images/flow.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "import openeo\n",
    "from openeo.extra.spectral_indices.spectral_indices import append_index\n",
    "from openeo.processes import array_element, normalized_difference\n",
    "\n",
    "from eo_utils import *\n",
    "import dask.array as da\n",
    "import xarray as xr\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'default_plan': 'early-adopter',\n",
       " 'info': {'default_plan': 'early-adopter',\n",
       "  'oidc_userinfo': {'acr': 'https://refeds.org/assurance/IAP/low',\n",
       "   'eduperson_assurance': ['https://aai.egi.eu/LoA#Low',\n",
       "    'https://refeds.org/assurance/IAP/low'],\n",
       "   'eduperson_entitlement': ['urn:mace:egi.eu:group:vo.openeo.cloud:role=vm_operator#aai.egi.eu',\n",
       "    'urn:mace:egi.eu:group:vo.openeo.cloud:role=member#aai.egi.eu',\n",
       "    'urn:mace:egi.eu:group:vo.openeo.cloud:role=early_adopter#aai.egi.eu'],\n",
       "   'email': 'sulova.andrea@gmail.com',\n",
       "   'email_verified': True,\n",
       "   'sub': '1edbae7adc053e5164b8ac7696e17a9ec031bf5a11fe6dce659cafe39a9366a2@egi.eu',\n",
       "   'voperson_verified_email': ['sulova.andrea@gmail.com']},\n",
       "  'roles': ['EarlyAdopter']},\n",
       " 'name': 'sulova.andrea@gmail.com',\n",
       " 'user_id': '1edbae7adc053e5164b8ac7696e17a9ec031bf5a11fe6dce659cafe39a9366a2@egi.eu'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connect with openeo backend\n",
    "connection = openeo.connect(\"openeo.cloud\")\n",
    "connection.authenticate_oidc()\n",
    "connection.describe_account()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Create an output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = pathlib.Path(\"output\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specify the Area of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6161552d19496884e856f8c853c022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[4.707, -73.987], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Colombbia\n",
    "center = [4.707, -73.987]\n",
    "# Denmark\n",
    "# center = [55.6, 12.5]\n",
    "zoom = 14\n",
    "eoMap = openMap(center,zoom)\n",
    "eoMap.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "west -74.27856445312501 \n",
      "east -73.02955627441408 \n",
      "south 4.601064939225764 \n",
      "north 4.874784352885875\n"
     ]
    }
   ],
   "source": [
    "bbox = eoMap.getBbox()\n",
    "spatial_extent  = {'west':bbox[0],'east':bbox[2],'south':bbox[1],'north':bbox[3],'crs':4326}\n",
    "print('west',bbox[0],'\\neast',bbox[2],'\\nsouth',bbox[1],'\\nnorth',bbox[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 ) *Sentinel-2 ARD Pre-Processing*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Specify collections :\n",
    "  \n",
    "  * **SENTINEL2_L1C** (EODC) - Missing Zenith Azimuth, support FORCE and Fmask\n",
    "\n",
    "  * **SENTINEL2_L1C_SENTINELHUB** (TerraScope backend) - supports SMAC and iCor atmospheric correction\n",
    "\n",
    "  * **boa_sentinel_2** (EODC) -  (ARD)  processed with FORCE. Missing Zenith and Azimuth information, cloud mask needs to be applied\n",
    "\n",
    "\n",
    "  * **SENTINEL2_L2A_SENTINELHUB** (TerraScope backend) - Having Zenith and Azimuth information,  (ARD) processed with sen2cor., cloud mask needs to be applied\n",
    "\n",
    "  Read more about ARD https://docs.openeo.cloud/usecases/ard/msi/#reference-implementations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![S2](images/S2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(connection.list_collections())\n",
    "# connection.list_processes()\n",
    "# connection.describe_collection(collection)\n",
    "\n",
    "# ARD\n",
    "# collection      = 'boa_sentinel_2'\n",
    "collection        = 'SENTINEL2_L2A_SENTINELHUB'\n",
    "\n",
    "# L1C\n",
    "# collection      = 'SENTINEL2_L1C'    \n",
    "# collection      = 'SENTINEL2_L1C_SENTINELHUB'\n",
    "# connection.describe_collection(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Specify temporal extent and bands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date      = '2022-01-07'\n",
    "end_date        = '2022-01-13'\n",
    "bands           = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09',  'B11', 'B12', 'CLP', 'SCL' , 'sunAzimuthAngles', 'sunZenithAngles'] \n",
    "\n",
    "# Bogota\n",
    "spatial_extent = {'west': -74.27856445312501 , 'east': 72.15713924157274, 'south': 4.40172965700321, 'north': 4.949216031685158}\n",
    "\n",
    "# Alps\n",
    "# spatial_extent = {'west': 4.3617128367019395, 'east': 10.013202094514442, 'south': 46.34565603628651, 'north': 48.133091757973475}\n",
    "\n",
    "# spatial_extent  = {'west':bbox[0],'east':bbox[2],'south':bbox[1],'north':bbox[3]}\n",
    "\n",
    "\n",
    "S2_cube = connection.load_collection(collection,\n",
    "                                     spatial_extent = spatial_extent,\n",
    "                                     temporal_extent = [start_date, end_date],\n",
    "                                     bands = bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) *Mask Clouds, Shadows and Snow*\n",
    "- atmospheric_correction: https://docs.openeo.cloud/usecases/ard/msi/#reference-implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: SCL + CLP\n",
    "\n",
    "# Scene classification data, based on Sen2Cor process\n",
    "# scl == 3    Cloud Shadows \n",
    "# scl == 8    Clouds medium probability\n",
    "# scl == 9    Clouds high probability\n",
    "# scl == 10   Cirrus\n",
    "# scl == 11   Snow / Ice\n",
    "\n",
    "scl = S2_cube.band(\"SCL\")\n",
    "mask = (scl == 3) | (scl == 8) | (scl == 9) | (scl == 10) |(scl == 11)\n",
    "S2_cube_scl = S2_cube.mask(mask)\n",
    "\n",
    "# CLP (cloud probabilities) based on s2cloudless\n",
    "clp = S2_cube.band(\"CLP\")\n",
    "clp = clp.resample_spatial(resolution=20, method = \"bicubic\")\n",
    "mask = (clp / 255) > 0.3  # 160m resolution s2cloudless so it does not have to use\n",
    "S2_cube = S2_cube_scl.mask(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: CLP Resample\n",
    "\n",
    "# CLP (cloud probabilities) based on s2cloudless\n",
    "clp = S2_cube.band(\"CLP\")\n",
    "clp = clp.resample_spatial(resolution=20, method = \"bicubic\")\n",
    "clp = (clp / 255) > 0.3  # 160m resolution s2cloudless so it does not have to use\n",
    "S2_cube = S2_cube.mask(clp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Examples of Cloud Masking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cloudMask](images/cloudMask.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) NDVI Calculation \n",
    "-   NDVI (Sentinel 2) = (B8 – B4) / (B8 + B4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_cube = append_index(S2_cube,\"NDVI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) NDWI Calculation \n",
    "\n",
    "-   NDWI (Sentinel 2) = (B3 – B8) / (B3 + B8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_cube = append_index(S2_cube,\"NDWI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) Mask Terrain Shadow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_code = \"\"\"\n",
    "\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "def rasterize(azimuth, transform=None):\n",
    "\n",
    "    azimuth = np.deg2rad(azimuth)\n",
    "    xdir, ydir = np.sin(azimuth), np.cos(azimuth)\n",
    "\n",
    "    if transform is not None:\n",
    "        xdir, ydir = transform * (xdir, ydir)\n",
    "        xdir -= transform.xoff\n",
    "        ydir -= transform.yoff\n",
    "\n",
    "    slope = ydir / xdir\n",
    "    if slope < 1. and slope > -1.:\n",
    "        xdir = 1.\n",
    "        ydir = slope\n",
    "    else:\n",
    "        xdir = 1. / slope\n",
    "        ydir = 1.\n",
    "    return xdir, ydir\n",
    "\n",
    "@jit('f8(f8, f8, f8)', nopython=True, nogil=True)\n",
    "def height(xbase, ybase, angle):\n",
    "\n",
    "    rho = (xbase**2 + ybase**2)**.5\n",
    "    return rho * np.tan(angle)\n",
    "\n",
    "\n",
    "@jit('boolean(f8, f8, Tuple((i8, i8)))', nopython=True, nogil=True)\n",
    "def within_bounds(pixel_x, pixel_y, bounds):\n",
    "\n",
    "    return (pixel_y < bounds[0]) and (pixel_x < bounds[1]) and (pixel_y > 0) and (pixel_x > 0)\n",
    "\n",
    "\n",
    "@jit('i8[:,:](f4[:,:], Tuple((f8,f8)), f8, Tuple((f8, f8)), i8, i8)', nopython=True, nogil=True)\n",
    "def hillshade(elevation_model, resolution, zenith, ray, ystart, yend):\n",
    "\n",
    "    if max(ray) != 1.:\n",
    "        raise ValueError(\"xy-direction is not rasterized.\")\n",
    "    shadow = np.zeros((yend - ystart, elevation_model.shape[1]), dtype=np.int64)\n",
    "    zenith = np.deg2rad(90 - zenith)\n",
    "    dx, dy = ray\n",
    "    xres, yres = resolution\n",
    "    z_max = elevation_model.max()\n",
    "    bounds = elevation_model.shape\n",
    "\n",
    "    for pixel_y in range(ystart, yend):\n",
    "        for pixel_x in range(elevation_model.shape[1]):\n",
    "\n",
    "            pixel_z = elevation_model[pixel_y, pixel_x]\n",
    "            ray_x = float(pixel_x)\n",
    "            ray_y = float(pixel_y)\n",
    "            intersection = None\n",
    "\n",
    "            while within_bounds(ray_x, ray_y, bounds):\n",
    "                xbase = (ray_x - pixel_x) * xres\n",
    "                ybase = (ray_y - pixel_y) * yres\n",
    "                ray_z = height(xbase, ybase, zenith) + pixel_z\n",
    "                if ray_z > z_max:\n",
    "                    break\n",
    "                if ray_z < elevation_model[int(ray_y), int(ray_x)]:\n",
    "                    intersection = (ray_y, ray_x)\n",
    "                    break\n",
    "                ray_x += dx\n",
    "                ray_y += dy\n",
    "\n",
    "            if intersection is not None:\n",
    "                shadow[pixel_y - ystart, pixel_x] = 1\n",
    "    return shadow\n",
    "\n",
    "\n",
    "def _run_shader(sun_zenith, sun_azimuth, elevation_model, resolution_x, resolution_y, dem_transform):\n",
    "\n",
    "    shadow_stack = np.zeros(sun_azimuth.shape)\n",
    "\n",
    "    for step in range(sun_azimuth.shape[0]):\n",
    "        azimuth = np.nanmean(sun_azimuth[step, ...])\n",
    "        zenith = np.nanmean(sun_zenith[step, ...])\n",
    "        if np.all(np.isnan(zenith)):\n",
    "            continue\n",
    "        # Convert the azimuth into its components on the XY-plane\n",
    "        ray_xdir, ray_ydir = rasterize(azimuth, dem_transform)\n",
    "\n",
    "        # Assume chunking is already done by Dask\n",
    "        ystart = 0\n",
    "        yend = elevation_model.shape[1]\n",
    "        # Make sure inputs have the right data type\n",
    "        resolution = (float(resolution_x), float(resolution_y))\n",
    "        zenith = float(zenith)\n",
    "        ray = (float(ray_xdir), float(ray_ydir))\n",
    "\n",
    "        shadow = hillshade(elevation_model[0, ].astype(np.float32),\n",
    "                           resolution,\n",
    "                           zenith,\n",
    "                           ray,\n",
    "                           ystart,\n",
    "                           yend)\n",
    "        shadow_stack[step, ...] = shadow.astype(np.int16).reshape(elevation_model.shape)\n",
    "\n",
    "    shadow_stack[np.isnan(sun_azimuth)] = 255\n",
    "    return shadow_stack\n",
    "\n",
    "\n",
    "def terrain_shadow_mask(dem, sun_zenith, sun_azimuth, dem_transform, dem_resolution):\n",
    "\n",
    "    dem_overlapped = da.overlap.overlap(dem.data, depth={0: 0, 1: 10, 2: 10}, boundary=0)\n",
    "    sun_azimuth_overlapped = da.overlap.overlap(sun_azimuth.data,\n",
    "                                                depth={0: 0, 1: 10, 2: 10},\n",
    "                                                boundary=0)\n",
    "    sun_zenith_overlapped = da.overlap.overlap(sun_zenith.data,\n",
    "                                               depth={0: 0, 1: 10, 2: 10},\n",
    "                                               boundary=0)\n",
    "    shadow_overlapped = da.map_blocks(_run_shader,\n",
    "                                      sun_zenith_overlapped,\n",
    "                                      sun_azimuth_overlapped,\n",
    "                                      dem_overlapped,\n",
    "                                      dem_resolution[0],\n",
    "                                      dem_resolution[1],\n",
    "                                      dem_transform)\n",
    "    shadow_da = da.overlap.trim_internal(shadow_overlapped, {0: 0, 1: 10, 2: 10})\n",
    "    shadow = sun_zenith.copy(data=shadow_da).astype(np.int16)\n",
    "\n",
    "    shadow = shadow.rio.set_nodata(255)\n",
    "    return shadow\n",
    "\"\"\"\n",
    "\n",
    "S2_cube = S2_cube.apply_dimension(code = udf_code, runtime = \"Python\", dimension =\"t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E) *Create Monthly Best-Pixel Mosaic*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2_median_cube = S2_cube.median_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check & download results: https://editor.openeo.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': send 'start'\n",
      "0:00:16 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:00:23 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:00:32 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:00:41 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:00:52 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:01:06 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:01:23 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:01:44 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:02:09 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:02:39 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:03:18 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:04:06 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:05:06 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:06:08 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:07:10 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:08:12 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': queued (progress N/A)\n",
      "0:09:13 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:10:14 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:11:15 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:12:17 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:13:18 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:14:19 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:15:23 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:16:25 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:17:27 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:18:29 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:19:30 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:20:31 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:21:32 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:22:33 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:23:35 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:24:37 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:25:39 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:26:41 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:27:44 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:28:45 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:29:46 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:30:48 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:31:49 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:32:50 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:33:52 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:34:53 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:35:56 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:36:58 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:38:00 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:39:01 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:40:02 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:41:04 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:42:05 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:43:07 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:44:08 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:45:10 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:46:12 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:47:14 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:48:16 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:49:18 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:50:20 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:51:24 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:52:26 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:53:27 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:54:28 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:55:30 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:56:32 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:57:33 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:58:35 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "0:59:37 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:00:38 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:01:40 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:02:41 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:03:42 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:04:43 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:05:45 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:06:47 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:07:48 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:08:50 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:09:52 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:10:53 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:11:54 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:12:56 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:13:58 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:14:59 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:16:00 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:17:02 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:18:03 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:19:05 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:20:07 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:21:09 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:22:10 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:23:12 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:24:13 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:25:15 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:26:17 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:27:18 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:28:19 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:29:21 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:30:23 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:31:24 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:32:25 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:33:26 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:34:27 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:35:29 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:36:30 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:37:31 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:38:32 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:39:34 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:40:36 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:41:37 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:42:38 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:43:39 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:44:41 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:45:42 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:46:44 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:47:45 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:48:46 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:49:49 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:50:51 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:51:52 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:52:53 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:53:54 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:54:56 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:55:57 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:56:59 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:58:00 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "1:59:01 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "2:00:02 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "2:01:04 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "2:02:07 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "2:03:08 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "2:04:09 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "2:05:11 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "2:06:13 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "2:07:14 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "2:08:17 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "2:09:31 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "2:10:36 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': running (progress N/A)\n",
      "2:11:50 Job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0': error (progress N/A)\n",
      "\n",
      "Your batch job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0' failed.\n",
      "Logs can be inspected in an openEO (web) editor or with `connection.job('vito-93994139-fb8b-4c87-afd9-7888d32070b0').logs()`.\n",
      "\n",
      "Printing logs:\n",
      "[{'id': 'error', 'level': 'error', 'message': 'error processing batch job\\nTraceback (most recent call last):\\n  File \"batch_job.py\", line 319, in main\\n    run_driver()\\n  File \"batch_job.py\", line 292, in run_driver\\n    run_job(\\n  File \"/data1/hadoop/yarn/local/usercache/sulova/appcache/application_1654680813887_0135/container_e5039_1654680813887_0135_01_000010/venv/lib/python3.8/site-packages/openeogeotrellis/utils.py\", line 41, in memory_logging_wrapper\\n    return function(*args, **kwargs)\\n  File \"batch_job.py\", line 388, in run_job\\n    assets_metadata = result.write_assets(str(output_file))\\n  File \"/data1/hadoop/yarn/local/usercache/sulova/appcache/application_1654680813887_0135/container_e5039_1654680813887_0135_01_000010/venv/lib/python3.8/site-packages/openeo_driver/save_result.py\", line 110, in write_assets\\n    return self.cube.write_assets(filename=directory, format=self.format, format_options=self.options)\\n  File \"/data1/hadoop/yarn/local/usercache/sulova/appcache/application_1654680813887_0135/container_e5039_1654680813887_0135_01_000010/venv/lib/python3.8/site-packages/openeogeotrellis/geopysparkdatacube.py\", line 1582, in write_assets\\n    self._get_jvm().org.openeo.geotrellis.geotiff.package.saveRDD(max_level.srdd.rdd(),band_count,str(filePath),zlevel,self._get_jvm().scala.Option.apply(crop_extent),gtiff_options)\\n  File \"/opt/spark3_2_0/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py\", line 1309, in __call__\\n    return_value = get_return_value(\\n  File \"/opt/spark3_2_0/python/lib/py4j-0.10.9.2-src.zip/py4j/protocol.py\", line 326, in get_return_value\\n    raise Py4JJavaError(\\npy4j.protocol.Py4JJavaError: An error occurred while calling z:org.openeo.geotrellis.geotiff.package.saveRDD.\\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 148.0 failed 4 times, most recent failure: Lost task 2.3 in stage 148.0 (TID 95762) (epod147.vgt.vito.be executor 1558): java.lang.NoClassDefFoundError: Could not initialize class org.openeo.geotrellis.layers.FileLayerProvider$\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat java.lang.invoke.SerializedLambda.readResolve(SerializedLambda.java:230)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat java.io.ObjectStreamClass.invokeReadResolve(ObjectStreamClass.java:1274)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2195)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readArray(ObjectInputStream.java:2092)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1654)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:502)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:460)\\n\\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)\\n\\tat sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2295)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:502)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:460)\\n\\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)\\n\\tat sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2295)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:502)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:460)\\n\\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)\\n\\tat sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2295)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readArray(ObjectInputStream.java:2092)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1654)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:502)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:460)\\n\\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)\\n\\tat sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2295)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:502)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:460)\\n\\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)\\n\\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:115)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:85)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\tat java.lang.Thread.run(Thread.java:748)\\n\\nDriver stacktrace:\\n\\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2403)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2352)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2351)\\n\\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\\n\\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\\n\\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2351)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1109)\\n\\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1109)\\n\\tat scala.Option.foreach(Option.scala:407)\\n\\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1109)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2591)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2533)\\n\\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2522)\\n\\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\\n\\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:898)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2235)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2254)\\n\\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\\n\\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\n\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\\n\\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\\n\\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$collectAsMap$1(PairRDDFunctions.scala:737)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\\n\\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\\n\\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\\n\\tat org.apache.spark.rdd.PairRDDFunctions.collectAsMap(PairRDDFunctions.scala:736)\\n\\tat org.openeo.geotrellis.geotiff.package$.getCompressedTiles(package.scala:290)\\n\\tat org.openeo.geotrellis.geotiff.package$.saveRDDGeneric(package.scala:216)\\n\\tat org.openeo.geotrellis.geotiff.package$.saveRDD(package.scala:156)\\n\\tat org.openeo.geotrellis.geotiff.package.saveRDD(package.scala)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\\n\\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\\n\\tat py4j.Gateway.invoke(Gateway.java:282)\\n\\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\\n\\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\\n\\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\\n\\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: java.lang.NoClassDefFoundError: Could not initialize class org.openeo.geotrellis.layers.FileLayerProvider$\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat java.lang.invoke.SerializedLambda.readResolve(SerializedLambda.java:230)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\\n\\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat java.io.ObjectStreamClass.invokeReadResolve(ObjectStreamClass.java:1274)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2195)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readArray(ObjectInputStream.java:2092)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1654)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:502)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:460)\\n\\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)\\n\\tat sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2295)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:502)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:460)\\n\\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)\\n\\tat sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2295)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:502)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:460)\\n\\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)\\n\\tat sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2295)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readArray(ObjectInputStream.java:2092)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1654)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:502)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:460)\\n\\tat scala.collection.immutable.List$SerializationProxy.readObject(List.scala:488)\\n\\tat sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1184)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2295)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2404)\\n\\tat java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2328)\\n\\tat java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2186)\\n\\tat java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1666)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:502)\\n\\tat java.io.ObjectInputStream.readObject(ObjectInputStream.java:460)\\n\\tat org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)\\n\\tat org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:115)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:85)\\n\\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\\n\\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\\n\\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\\n\\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\\n\\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\\n\\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\\n\\t... 1 more\\n\\n'}]\n"
     ]
    },
    {
     "ename": "JobFailedException",
     "evalue": "Batch job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0' didn't finish successfully. Status: error (after 2:12:17).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJobFailedException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13492\\478971363.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mS2_median_cube\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mS2_median_cube\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'GTiff'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#GTiff #netCDF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmy_job\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mS2_median_cube\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_job\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"S2_L2A\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_and_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;34m\"S2_L2A\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ansu\\Anaconda3\\envs\\openEO\\lib\\site-packages\\openeo\\rest\\job.py\u001b[0m in \u001b[0;36mstart_and_wait\u001b[1;34m(self, print, max_poll_interval, connection_retry_interval, soft_error_max)\u001b[0m\n\u001b[0;32m    216\u001b[0m             raise JobFailedException(\"Batch job {i!r} didn't finish successfully. Status: {s} (after {t}).\".format(\n\u001b[0;32m    217\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melapsed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m             ), job=self)\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJobFailedException\u001b[0m: Batch job 'vito-93994139-fb8b-4c87-afd9-7888d32070b0' didn't finish successfully. Status: error (after 2:12:17)."
     ]
    }
   ],
   "source": [
    "# Send cube to server\n",
    "S2_median_cube = S2_median_cube.save_result(format='GTiff') #GTiff #netCDF\n",
    "my_job  = S2_median_cube.send_job(title=\"S2_L2A\")\n",
    "results = my_job.start_and_wait().get_results()\n",
    "\n",
    "results.download_files(out_dir/\"S2_L2A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdalinfo -hist output/openEO.nc\n",
    "S2_L2A = xr.open_dataset(out_dir/'S2_L2A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) *Sentinel-1 ARD Pre-Processing*\n",
    "\n",
    "Load Collection of Sentinel-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cat](images/S1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_cube = connection.load_collection('SENTINEL1_GRD', \n",
    "                                     spatial_extent = spatial_extent, \n",
    "                                     temporal_extent = [start_date, end_date], \n",
    "                                     bands = ['VH','VV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A)  Analysis-Ready-Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_cube = S1_cube.ard_normalized_radar_backscatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B) Mask Urban Areas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldcover_cube = connection.load_collection(\"ESA_WORLDCOVER_10M_2020_V1\", \n",
    "                                            temporal_extent = [start_date, end_date], \n",
    "                                            spatial_extent = spatial_extent, \n",
    "                                            bands = [\"MAP\"])\n",
    "                                            #.filter_bbox({'west':bbox[0],'east':bbox[2],'south':bbox[1],'north':bbox[3]})\n",
    "\n",
    "builtup_mask = worldcover_cube.band(\"MAP\") != 50\n",
    "S1_cube = S1_cube.mask(builtup_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B) Mask Radar Shadows*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C) Mask Sentinel-1 Exclusion Layer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*D) Create Monthly Median Mosaic*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_median_cube = S1_cube.median_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check & download results: https://editor.openeo.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_median_cube = S1_median_cube.save_result(format='GTiff') #GTiff #netCDF\n",
    "my_job  = S1_median_cube.send_job(title=\"S1_ARD\")\n",
    "results = my_job.start_and_wait().get_results()\n",
    "\n",
    "results.download_files(out_dir/'S1_ARD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Water Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cat](images/WM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load LUT and run logistic expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_code =\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "## Note this will be updated. Currently demonstration only. \n",
    "## The lookup table defines bands and logistic regression expressions \n",
    "## for each ecoregion.\n",
    "LOOKUPTABLE = {\n",
    "    'tropical': \n",
    "    {\n",
    "        'S1': {'bands': ['VV'], \n",
    "               'expression': lambda VV: 1 / (1 + np.exp(- (-7.17 + (-0.48 * VV))))},\n",
    "        'S2': {'bands': ['NDVI', 'NDWI'], \n",
    "               'expression': lambda NDVI, NDWI: 1 / (1 + np.exp(- (0.845 + (2.14 * NDVI) + (-13.5 * NDWI))))},\n",
    "        'S2_S1': {'bands': ['VV', 'NDWI'], \n",
    "                  'expression': lambda VV, NDWI: 1 / (1 + np.exp(- (-2.64 + (-0.23 * VV) + (-8.6 * NDWI))))},\n",
    "     },\n",
    "    \n",
    "    'subtropical':\n",
    "    {\n",
    "        'S1': {'bands': ['VV', 'VH'], \n",
    "               'expression': lambda VV, VH: 1 / (1 + np.exp(- (-8.1 + (-0.13 * VV) + (-0.27 * VH))))},\n",
    "        'S2': {'bands': ['NDVI', 'NDWI'], \n",
    "               'expression': lambda NDVI, NDWI: 1 / (1 + np.exp(- (1.267 + (0.316 * NDVI) + (-11 * NDWI))))},\n",
    "        'S2_S1': {'bands': ['VV', 'NDWI'], \n",
    "                  'expression': lambda VV, NDWI: 1 / (1 + np.exp(- (-2.64 + (-0.23 * VV) + (-8.6 * NDWI))))},\n",
    "    }\n",
    "}\n",
    "    \n",
    "    \n",
    "def _create_img(expr_dict, dataset, sensor_value):\n",
    "    \n",
    "    # lambda expression to create surface water probability\n",
    "    exp = expr_dict['expression']\n",
    "    \n",
    "    # bands required as input to the lambda expression\n",
    "    bands = expr_dict['bands']\n",
    "    \n",
    "    # filter the dictionary to required bands identified above. \n",
    "    filtered_dict = dict((k, dataset[k]) for k in bands)\n",
    "    \n",
    "    # Calculate the probability using the input dataset and lambda expression.\n",
    "    probability = (exp(**filtered_dict)*100).astype(np.uint8)\n",
    "    \n",
    "    # Create the QA band with sensor value.\n",
    "    sensor_rank = xr.full_like(probability, sensor_value)\n",
    "    \n",
    "    # create an empty dataset and add the probability and sensor_rank outputs.\n",
    "    ds = xr.Dataset()\n",
    "    ds['probability'] = probability\n",
    "    ds['sensor_rank'] = sensor_rank\n",
    "\n",
    "    return ds    \n",
    "\n",
    "def _water_mask(dataset, region_parameters):\n",
    "    \n",
    "    composite = xr.where(\n",
    "        \n",
    "        # Where valid data for both S2 and S1.\n",
    "        xr.ufuncs.logical_and(~dataset['S2_mask'], ~dataset['S1_mask']), \n",
    "        \n",
    "        # Create water mask with sensor_value 5\n",
    "        _create_img(region_parameters['S2_S1'], dataset, 5),\n",
    "        \n",
    "        # Else\n",
    "        xr.where(\n",
    "            \n",
    "            # Where Sentinel-2 data is valid.\n",
    "            ~dataset['S2_mask'], \n",
    "            \n",
    "            # Create water mask from sentinel-2 with sensor value 4.\n",
    "            _create_img(region_parameters['S2'], dataset, 4),\n",
    "            \n",
    "            # If no Sentinel-2 data, use Sentinel-1 on it's own. Sensor value 3.\n",
    "            _create_img(region_parameters['S1'], dataset, 3), \n",
    "            )    \n",
    "        )    \n",
    "    \n",
    "    return composite\n",
    "\n",
    "def water_mask(dataset, ecoregion):\n",
    "   \n",
    "    # Access the parameters required for that ecoregion.\n",
    "    region_parameters = LOOKUPTABLE[ecoregion]\n",
    "    \n",
    "    # Create the water mask.\n",
    "    composite = _water_mask(dataset, region_parameters)\n",
    "\n",
    "    return composite\n",
    "\"\"\"\n",
    "\n",
    "S1 = S1_median_cube.apply_dimension(code = udf_code, runtime = \"Python\", dimension = \"t\")  \n",
    "S2 = S2_median_cube.apply_dimension(code = udf_code, runtime = \"Python\", dimension = \"t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rank and produce final water map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check & download results: https://editor.openeo.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_S2 = S1_S2.save_result(format='GTiff') #GTiff #netCDF\n",
    "my_job  = S1_S2.send_job(title=\"S1_ARD\")\n",
    "results = my_job.start_and_wait().get_results()\n",
    "\n",
    "results.download_files(out_dir/'S1_ARD')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bac3ed2dc488f2c378e3bf5b6869692f562f2ddad183c0dcb5bc297978f34f8d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('openEO')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
